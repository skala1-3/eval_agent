# agents/seraph_agent.py (SerpApi ë²„ì „ + JSON ì €ì¥ + LangGraph í˜¸í™˜)
import os, json, logging
from serpapi import GoogleSearch
from dotenv import load_dotenv
from typing import List, Dict, Any
from graph.state import PipelineState, CompanyMeta

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¡œê¹… ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")


class SeraphAgent:
    def __init__(self):
        load_dotenv()
        self.api_key = os.getenv("SERPAPI_KEY")
        if not self.api_key:
            raise ValueError("âŒ SERPAPI_KEY not found in .env file")

    def _search_google(self, query: str, num_results: int = 20) -> List[Dict[str, Any]]:
        """SerpApië¥¼ ì´ìš©í•´ AI ê¸ˆìœµ ìŠ¤íƒ€íŠ¸ì—… í›„ë³´ ê²€ìƒ‰"""
        logging.info(f"ğŸ” Searching Google (via SerpApi) for: {query}")
        search = GoogleSearch({
            "q": query,
            "num": num_results,
            "hl": "en",
            "engine": "google",
            "api_key": self.api_key
        })
        results = search.get_dict().get("organic_results", [])
        return [
            {
                "name": r.get("title", ""),
                "url": r.get("link", ""),
                "summary": r.get("snippet", "")
            }
            for r in results if r.get("link")
        ]

    def __call__(self, state: PipelineState) -> PipelineState:
        """LangGraphì—ì„œ ì‹¤í–‰ë  ë©”ì¸ í˜¸ì¶œ í•¨ìˆ˜"""
        logging.info("--- ğŸš€ Starting SeraphAgent (SerpApi-Google) ---")

        # 1ï¸âƒ£ ê²€ìƒ‰ ìˆ˜í–‰
        raw = self._search_google(state.query)

        # 2ï¸âƒ£ ê²€ìƒ‰ ê²°ê³¼ë¥¼ CompanyMetaë¡œ ë§¤í•‘
        company_metas = [
            CompanyMeta(
                id=f"cand_{i+1:02d}",
                name=c["name"],
                website=c["url"],
                tags=[c["summary"]] if c["summary"] else [],
            )
            for i, c in enumerate(raw)
        ]

        # 3ï¸âƒ£ state ì—…ë°ì´íŠ¸
        state.companies = company_metas
        logging.info(f"âœ… Retrieved {len(company_metas)} candidates from Google search.")

        # 4ï¸âƒ£ ê²°ê³¼ ì €ì¥ (data/raw/candidates.json)
        try:
            # run.py ì‹¤í–‰ í™˜ê²½ì—ì„œë„ ì•ˆì •ì ìœ¼ë¡œ ê²½ë¡œ ì¸ì‹
            project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
            output_dir = os.path.join(project_root, "data", "raw")
            os.makedirs(output_dir, exist_ok=True)
            output_path = os.path.join(output_dir, "candidates.json")

            with open(output_path, "w", encoding="utf-8") as f:
                json.dump([c.model_dump() for c in company_metas], f, indent=2, ensure_ascii=False)

            logging.info(f"ğŸ’¾ Saved candidates to {output_path}")

        except Exception as e:
            logging.error(f"âš ï¸ Failed to save candidates.json: {e}")

        return state


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë…ë¦½ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš©)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    # ë‹¨ë… í…ŒìŠ¤íŠ¸ ì‹œ: state ê°ì²´ ìƒì„± â†’ ì‹¤í–‰
    test_state = PipelineState(query="AI fintech robo-advisory wealth management startup")
    test_agent = SeraphAgent()
    final_state = test_agent(test_state)

    print(f"âœ… {len(final_state.companies)} candidates saved to data/raw/candidates.json")
